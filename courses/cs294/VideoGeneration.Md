### Conditional Control
N.d., [2302.05543] Adding Conditional Control to Text-to-Image Diffusion Models, [paper](https://arxiv.org/abs/2302.05543)
### VideoGPT
2021.09, VideoGPT: Video Generation using VQ-VAE and Transformers, [paper](http://arxiv.org/abs/2104.10157)
### SDEdit
2022.01, SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations, [paper](http://arxiv.org/abs/2108.01073)
### Language Model Architecture
2022.04, What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?, [paper](http://arxiv.org/abs/2204.05832)
### MaskViT
2022.08, MaskViT: Masked Visual Pre-Training for Video Prediction, [paper](http://arxiv.org/abs/2206.11894)
### TATS
arXiv  2022.09, Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer, [paper](http://arxiv.org/abs/2204.03638) 
### Phenaki
arXiv  2022.10, Phenaki: Variable Length Video Generation From Open Domain Textual Description, [paper](http://arxiv.org/abs/2210.02399)

### LVDM
2022.11, Latent Video Diffusion Models for High-Fidelity Long Video Generation, [paper](https://arxiv.org/abs/2211.13221v2)

### Dreamix
2023.02, Dreamix: Video Diffusion Models are General Video Editors, [paper](http://arxiv.org/abs/2302.01329)
### ControlVideo
2023.05, ControlVideo: Training-free Controllable Text-to-Video Generation, [paper](http://arxiv.org/abs/2305.13077)
### Video Prediction Rewards
2023.05, Video Prediction Models as Rewards for Reinforcement Learning, [paper](http://arxiv.org/abs/2305.14343)
### Emu Video
2023.11, Emu Video: Factorizing Text-to-Video Generation by Explicit Image Conditioning, [paper](http://arxiv.org/abs/2311.10709)
### Universal Policies
2023.11, Learning Universal Policies via Text-Guided Video Generation, [paper](http://arxiv.org/abs/2302.00111)
### Conditional Control
2023.11, Adding Conditional Control to Text-to-Image Diffusion Models, [paper](http://arxiv.org/abs/2302.05543)
### Photorealistic Video Generation
2023.12, Photorealistic Video Generation with Diffusion Models, [paper](http://arxiv.org/abs/2312.06662)
### Interactive Real-World Simulators
2024.01, Learning Interactive Real-World Simulators, [paper](http://arxiv.org/abs/2310.06114)
### Lumiere
2024.02, Lumiere: A Space-Time Diffusion Model for Video Generation, [paper](http://arxiv.org/abs/2401.12945)
### RFM-1
2024.03, Introducing RFM-1: Giving robots human-like reasoning capabilities, [link](https://covariant.ai/insights/introducing-rfm-1-giving-robots-human-like-reasoning-capabilities/)
### Million-Length Video and Language
2024.03, World Model on Million-Length Video And Language With Blockwise RingAttention, [paper](http://arxiv.org/abs/2402.08268)
### VideoPoet
2024.03, VideoPoet: A Large Language Model for Zero-Shot Video Generation, [paper](http://arxiv.org/abs/2312.14125)
### Self-Supervised Spatio-Temporal Grounding
2024.05, What, when, and where? -- Self-Supervised Spatio-Temporal Grounding in Untrimmed Multi-Action Videos from Narrated Instructions, [paper](http://arxiv.org/abs/2303.16990)