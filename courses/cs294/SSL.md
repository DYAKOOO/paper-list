### Stacked Denoising Autoencoders
2010.05, Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion, No URL available
### Generalized Denoising Auto-Encoders
arXiv  2013.11, Generalized Denoising Auto-Encoders as Generative Models, [paper](http://arxiv.org/abs/1305.6663)
### Context Prediction
arXiv  2016.01, Unsupervised Visual Representation Learning by Context Prediction, [paper](http://arxiv.org/abs/1505.05192)
### Context Encoders
arXiv  2016.11, Context Encoders: Feature Learning by Inpainting, [paper](http://arxiv.org/abs/1604.07379)
### Split-Brain Autoencoders
arXiv  2017.04, Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction, [paper](http://arxiv.org/abs/1611.09842)
### Contrastive Predictive Coding (CPC)
arXiv  2019.01, Representation Learning with Contrastive Predictive Coding, [paper](http://arxiv.org/abs/1807.03748)
### Off-Policy Deep RL
arXiv  2019.08, Off-Policy Deep Reinforcement Learning without Exploration, [paper](http://arxiv.org/abs/1812.02900)
### MoCo
arXiv  2020.03, Momentum Contrast for Unsupervised Visual Representation Learning, [paper](http://arxiv.org/abs/1911.05722)
### SimCLR
arXiv  2020.06, A Simple Framework for Contrastive Learning of Visual Representations, [paper](http://arxiv.org/abs/2002.05709)
### Data-Efficient Image Recognition with CPC (CPCV2)
arXiv  2020.07, Data-Efficient Image Recognition with Contrastive Predictive Coding, [paper](http://arxiv.org/abs/1905.09272)
### BYOL
arXiv  2020.09, Bootstrap your own latent: A new approach to self-supervised Learning, [paper](http://arxiv.org/abs/2006.07733)
### CURL
arXiv  2020.09, CURL: Contrastive Unsupervised Representations for Reinforcement Learning, [paper](http://arxiv.org/abs/2004.04136)
### CLIP
arXiv  2021.02, Learning Transferable Visual Models From Natural Language Supervision, [paper](http://arxiv.org/abs/2103.00020)
### DINO
arXiv  2021.05, Emerging Properties in Self-Supervised Vision Transformers, [paper](http://arxiv.org/abs/2104.14294)
### Training Self-Supervised Vision Transformers
arXiv  2021.08, An Empirical Study of Training Self-Supervised Vision Transformers, [paper](http://arxiv.org/abs/2104.02057)
### SLIP
arXiv  2021.12, SLIP: Self-supervision meets Language-Image Pre-training, [paper](http://arxiv.org/abs/2112.12750)
### MVP
arXiv  2022.03, Masked Visual Pre-training for Motor Control, [paper](http://arxiv.org/abs/2203.06173)
### MultiMAE
arXiv  2022.04, MultiMAE: Multi-modal Multi-task Masked Autoencoders, [paper](http://arxiv.org/abs/2204.01678)
### Autonomous Machine Intelligence(Jepa)
2022.06, A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27, No URL available
### CoCa
arXiv  2022.06, CoCa: Contrastive Captioners are Image-Text Foundation Models, [paper](http://arxiv.org/abs/2205.01917)
### LiT
arXiv  2022.06, LiT: Zero-Shot Transfer with Locked-image text Tuning, [paper](http://arxiv.org/abs/2111.07991)
### BEiT
arXiv  2022.09, BEiT: BERT Pre-Training of Image Transformers, [paper](http://arxiv.org/abs/2106.08254)
### MaeMIM
arXiv  2022.10, Multimodal Masked Autoencoders Learn Transferable Representations, [paper](http://arxiv.org/abs/2205.14204)
### R3M
arXiv  2022.11, R3M: A Universal Visual Representation for Robot Manipulation, [paper](http://arxiv.org/abs/2203.12601)
### AudioMAE
arXiv  2023.01, Masked Autoencoders that Listen, [paper](http://arxiv.org/abs/2207.06405)
### FLIP
arXiv  2023.03, Scaling Language-Image Pre-training via Masking, [paper](http://arxiv.org/abs/2212.00794)
### I-JEPA
arXiv  2023.04, Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture, [paper](http://arxiv.org/abs/2301.08243)
### MTM
arXiv  2023.05, Masked Trajectory Models for Prediction, Representation, and Control, [paper](http://arxiv.org/abs/2305.02968)
### SiamMAE
arXiv  2023.05, Siamese Masked Autoencoders, [paper](http://arxiv.org/abs/2305.14344)
### Masked World Models(MWM)
arXiv  2023.05, Masked World Models for Visual Control, [paper](http://arxiv.org/abs/2206.14244)
### ImageBind
arXiv  2023.05, ImageBind: One Embedding Space To Bind Them All, [paper](http://arxiv.org/abs/2305.05665)
### Multi-View MAE
arXiv  2023.05, Multi-View Masked World Models for Visual Robotic Manipulation, [paper](http://arxiv.org/abs/2302.02408)
### BLIP-2
arXiv  2023.06, BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models, [paper](http://arxiv.org/abs/2301.12597)
### Sigmoid Loss CLIP (SigLIP)
Paris, France: IEEE  2023.10, Sigmoid Loss for Language Image Pre-Training, [paper](https://ieeexplore.ieee.org/document/10377550/)
### EmerDiff
arXiv  2024.01, EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models, [paper](http://arxiv.org/abs/2401.11739)
### DINOv2
arXiv  2024.02, DINOv2: Learning Robust Visual Features without Supervision, [paper](http://arxiv.org/abs/2304.07193)
### Feature Prediction from Video(V-JEPA)
arXiv  2024.02, Revisiting Feature Prediction for Learning Visual Representations from Video, [paper](http://arxiv.org/abs/2404.08471)
### Learning of Visual Robot Localization Using LED State Prediction 
arXiv  2024.02, Self-Supervised Learning of Visual Robot Localization Using LED State Prediction as a Pretext Task, [paper](http://arxiv.org/abs/2402.09886)