Here are the papers with escaped links and short titles:
### GAN
arXiv  2014.06, Generative Adversarial Networks, [paper](http://arxiv.org/abs/1406.2661)
### Deep Domain Confusion
arXiv  2014.12, Deep Domain Confusion: Maximizing for Domain Invariance, [paper](http://arxiv.org/abs/1412.3474)
### DCGAN
arXiv  2016.01, Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, [paper](http://arxiv.org/abs/1511.06434)
### Evaluation of Generative Models
arXiv  2016.04, A note on the evaluation of generative models, [paper](http://arxiv.org/abs/1511.01844)
### f-GAN
arXiv  2016.06, f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization, [paper](http://arxiv.org/abs/1606.00709)
### GAIL
arXiv  2016.06, Generative Adversarial Imitation Learning, [paper](http://arxiv.org/abs/1606.03476)
### Deep Directed Generative Models
arXiv  2016.06, Deep Directed Generative Models with Energy-Based Probability Estimation, [paper](http://arxiv.org/abs/1606.03439)
### Improved GAN Training
arXiv  2016.06, Improved Techniques for Training GANs, [paper](http://arxiv.org/abs/1606.03498)
### InfoGAN
arXiv  2016.06, InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets, [paper](http://arxiv.org/abs/1606.03657)
### EBGAN
arXiv  2017.03, Energy-based Generative Adversarial Network, [paper](http://arxiv.org/abs/1609.03126)
### Adversarial Feature Learning
arXiv  2017.04, Adversarial Feature Learning, [paper](http://arxiv.org/abs/1605.09782)
### Cramer Distance
arXiv  2017.05, The Cramer Distance as a Solution to Biased Wasserstein Gradients, [paper](http://arxiv.org/abs/1705.10743)
### Sinkhorn Divergences
arXiv  2017.10, Learning Generative Models with Sinkhorn Divergences, [paper](http://arxiv.org/abs/1706.00292)
### MMD GAN
arXiv  2017.11, MMD GAN: Towards Deeper Understanding of Moment Matching Network, [paper](http://arxiv.org/abs/1705.08584)
### WGAN
arXiv  2017.12, Wasserstein GAN, [paper](http://arxiv.org/abs/1701.07875)
### WGAN-GP
arXiv  2017.12, Improved Training of Wasserstein GANs, [paper](http://arxiv.org/abs/1704.00028)
### Flow-GAN
arXiv  2018.01, Flow-GAN: Combining Maximum Likelihood and Adversarial Learning in Generative Models, [paper](http://arxiv.org/abs/1705.08868)
### Two Time-Scale Update Rule
arXiv  2018.01, GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium, [paper](http://arxiv.org/abs/1706.08500)
### Spectral Normalization
arXiv  2018.02, Spectral Normalization for Generative Adversarial Networks, [paper](http://arxiv.org/abs/1802.05957)
### Progressive Growing of GANs
arXiv  2018.02, Progressive Growing of GANs for Improved Quality, Stability, and Variation, [paper](http://arxiv.org/abs/1710.10196)
### Optimal Transport GAN
arXiv  2018.03, Improving GANs Using Optimal Transport, [paper](http://arxiv.org/abs/1803.05573)
### VQ-VAE
arXiv  2018.05, Neural Discrete Representation Learning, [paper](http://arxiv.org/abs/1711.00937)
### IMLE
arXiv  2018.10, Implicit Maximum Likelihood Estimation, [paper](http://arxiv.org/abs/1809.09087)
### pix2pix
arXiv  2018.11, Image-to-Image Translation with Conditional Adversarial Networks, [paper](http://arxiv.org/abs/1611.07004)
### Video-to-Video Synthesis
arXiv  2018.12, Video-to-Video Synthesis, [paper](http://arxiv.org/abs/1808.06601)
### BigGAN
arXiv  2019.02, Large Scale GAN Training for High Fidelity Natural Image Synthesis, [paper](http://arxiv.org/abs/1809.11096)
### StyleGAN
arXiv  2019.03, A Style-Based Generator Architecture for Generative Adversarial Networks, [paper](http://arxiv.org/abs/1812.04948)
### SAGAN
arXiv  2019.06, Self-Attention Generative Adversarial Networks, [paper](http://arxiv.org/abs/1805.08318)
### Everybody Dance Now
arXiv  2019.08, Everybody Dance Now, [paper](http://arxiv.org/abs/1808.07371)
### IMLE for Diverse Image Synthesis
arXiv  2019.08, Diverse Image Synthesis from Semantic Layouts via Conditional IMLE, [paper](http://arxiv.org/abs/1811.12373)
### Prescribed GAN
arXiv  2019.10, Prescribed Generative Adversarial Networks, [paper](http://arxiv.org/abs/1910.04302)
### VIB
arXiv  2019.10, Deep Variational Information Bottleneck, [paper](http://arxiv.org/abs/1612.00410)
### BigBiGAN
arXiv  2019.11, Large Scale Adversarial Representation Learning, [paper](http://arxiv.org/abs/1907.02544)
### SPADE
arXiv  2019.11, Semantic Image Synthesis with Spatially-Adaptive Normalization, [paper](http://arxiv.org/abs/1903.07291)
### StyleGAN2
arXiv  2020.03, Analyzing and Improving the Image Quality of StyleGAN, [paper](http://arxiv.org/abs/1912.04958)
### BiGAN
arXiv  2020.06, Bidirectional Generative Modeling Using Adversarial Gradient Estimation, [paper](http://arxiv.org/abs/2002.09161)
### VAIL
arXiv  2020.08, Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow, [paper](http://arxiv.org/abs/1810.00821)
### TimeGAN
arXiv  2020.09, Time-series Imputation and Prediction with Bi-Directional Generative Adversarial Networks, [paper](http://arxiv.org/abs/2009.08900)
### VQ-GAN
arXiv  2021.06, Taming Transformers for High-Resolution Image Synthesis, [paper](http://arxiv.org/abs/2012.09841)
### GAN as Energy-based Model
arXiv  2021.07, Your GAN is Secretly an Energy-based Model and You Should use Discriminator Driven Latent Sampling, [paper](http://arxiv.org/abs/2003.06060)
### StyleGAN-XL
arXiv  2022.05, StyleGAN-XL: Scaling StyleGAN to Large Diverse Datasets, [paper](http://arxiv.org/abs/2202.00273)
### Improved VQGAN
arXiv  2022.06, Vector-quantized Image Modeling with Improved VQGAN, [paper](http://arxiv.org/abs/2110.04627)
### Chain-of-Thought Prompting
### Scaling GANs for Text-to-Image
arXiv  2023.06, Scaling up GANs for Text-to-Image Synthesis, [paper](http://arxiv.org/abs/2303.05511)
